{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "from IPython.display import HTML, display\n",
    "#import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "data_path = os.path.join('dashboard','dashboard-results.yml')\n",
    "with open(data_path, 'r') as stream:\n",
    "    try:\n",
    "        data = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(data,metric,submetric=None):\n",
    "    if submetric:\n",
    "        return([o['metrics'][metric][submetric] if 'metrics' in o and metric in o['metrics'] and submetric in o['metrics'][metric] else 0 for o in data['ontologies']])\n",
    "    else:\n",
    "        return([o['metrics'][metric] if 'metrics' in o and metric in o['metrics'] else 0 for o in data['ontologies']])\n",
    "\n",
    "\n",
    "m_onts = [o['namespace'] for o in data['ontologies']]\n",
    "m_syntax = [o['metrics']['Info: Syntax'] if 'metrics' in o and 'Info: Syntax' in o['metrics'] else \"unknown\" for o in data['ontologies']]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'ontology': m_onts, \n",
    "    'axioms': extract_number(data,'Axioms: Number of axioms'), \n",
    "    'classes': extract_number(data,'Entities: Number of classes'), \n",
    "    'entities_reused': extract_number(data,'Entities: % of entities reused'),\n",
    "    'uses': extract_number(data,'Info: How many ontologies use it?'),\n",
    "    'score': extract_number(data,'Info: Experimental OBO score','oboscore'),\n",
    "    'score_dash': extract_number(data,'Info: Experimental OBO score','_dashboard'),\n",
    "   # 'score_reuse': extract_number(data,'Info: Experimental OBO score','_reuse'),\n",
    "    'score_impact': extract_number(data,'Info: Experimental OBO score','_impact'),\n",
    "    #'score_impact_external': extract_number(data,'Info: Experimental OBO score','_impact_external'),\n",
    "    'syntax': m_syntax\n",
    "})\n",
    "\n",
    "df_all = pd.json_normalize(data['ontologies'])\n",
    "\n",
    "#Info: Breakdown of OWL class expressions used\n",
    "#results\n",
    "def plot_bar(df, feature, logx=True):\n",
    "    df.sort_values(by=feature,inplace=True)\n",
    "    height = 300+(len(df)*10)\n",
    "    fig = px.bar(df, y=\"ontology\", x=feature, orientation='h', width=800,height=height, log_x=logx)\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(\n",
    "            title='ontology',\n",
    "            tickmode='linear')\n",
    "    )\n",
    "\n",
    "    fig.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBO Foundry dashboard analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<a href=\"index.html\">Back to dashboard main page</a>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_breakdown(df_all, col_prefix):\n",
    "    df_axiom_types = df_all[[col for col in df_all if (col.startswith(col_prefix))]].copy()\n",
    "    df_axiom_types['o']=df_all['namespace']  \n",
    "    df_axiom_types.columns = [col.replace(col_prefix,\"\") for col in df_axiom_types]\n",
    "    df_axiom_types.fillna(0,inplace=True)\n",
    "    dt_info=df_axiom_types.describe().T\n",
    "    dt_info['count']=df_axiom_types.astype(bool).sum(axis=0)\n",
    "    dt_info.sort_values(by='count',inplace=True, ascending=False)\n",
    "    return dt_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_results = []\n",
    "for o in data['ontologies']:\n",
    "    if 'results' in o:\n",
    "        for res in o['results']:\n",
    "            if res.startswith(\"FP\"):\n",
    "                dashboard_results.append([o['namespace'], res, o['results'][res]['status']])\n",
    "df_results = pd.DataFrame(dashboard_results,columns=['ontology', 'check', 'status'])\n",
    "df_results_agg = df_results.groupby(['check','status']).agg(['count'])\n",
    "df_results_agg = df_results_agg.add_suffix('_Count').reset_index()\n",
    "df_results_agg.columns = ['check','status','count']\n",
    "\n",
    "dfx=df_results_agg.pivot(index='check', columns='status', values='count')\n",
    "dfx.index\n",
    "dfx.reset_index(inplace=True)\n",
    "dfx.fillna(0,inplace=True)\n",
    "dfx = pd.melt(dfx, id_vars='check', value_vars=['ERROR', 'INFO', 'PASS','WARN'])\n",
    "dfx['value']=dfx['value'].astype(int)\n",
    "dfx['status'] = dfx['status'].astype('category')\n",
    "errcats = ['PASS', 'INFO','WARN','ERROR']\n",
    "errcats.reverse()\n",
    "dfx['status'].cat.reorder_categories(errcats, inplace=True)\n",
    "dfx.sort_values(['check','status'], ascending=False, inplace=True)\n",
    "\n",
    "height = 300+(len(df_results_agg)*10)\n",
    "color_map_errors={'PASS': '#c3e6cb', 'INFO': '#bee5eb', 'WARN': '#ffeeba', 'ERROR': '#f5c6cb'}\n",
    "fig = px.bar(dfx, y=\"check\", x='value', labels={\"check\": \"OBO Principle\", \"value\": \"Number of ontologies\"}, color='status', orientation='h', width=800,height=height, color_discrete_map=color_map_errors)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>Ontologies by number of axioms</h3>'))\n",
    "plot_bar(df, \"axioms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>Ontologies by number of classes</h3>'))\n",
    "plot_bar(df, \"classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>Ontologies by how many ontologies use it</h3>'))\n",
    "plot_bar(df, \"uses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>Different serialisations used</h3>'))\n",
    "df['syntax'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>Breakdown of used Axiom Types</h3>'))\n",
    "display(HTML(table_breakdown(df_all,'metrics.Axioms: Breakdown of axiom types.').to_html()))\n",
    "\n",
    "display(HTML('<h3>Breakdown of used OWL Class Expression constructs</h3>'))\n",
    "display(HTML(table_breakdown(df_all,'metrics.Info: Breakdown of OWL class expressions used.').to_html()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#,'score_reuse', 'score_impact_external'\n",
    "df_score = df[['ontology','score','score_dash','score_impact']].copy()\n",
    "#df_score=\n",
    "df_score.sort_values('score',inplace=True, ascending=False)\n",
    "\n",
    "display(HTML('<h3>OBO Score (Experimental)</h3>'))\n",
    "display(HTML(df_score.to_html()))\n",
    "display(HTML('<h4>OBO Score Summary</h4>'))\n",
    "display(HTML(df_score.describe().T.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dependencies = dict()\n",
    "for o in data['ontologies']:\n",
    "    if 'metrics' in o:\n",
    "        if 'Info: Which ontologies use it?' in o['metrics']:\n",
    "            dependencies[o['namespace']] = o['metrics']['Info: Which ontologies use it?']\n",
    "            \n",
    "G=nx.DiGraph()\n",
    "#for o in dependencies:\n",
    "#    if len(dependencies[o])>1:\n",
    "#        G.add_node(o)\n",
    "for o in dependencies:\n",
    "    if len(dependencies[o])>1:\n",
    "        for dep in dependencies[o]:\n",
    "            G.add_edge(o,dep)\n",
    "\n",
    "#nx.draw(G, with_labels=True, font_weight='bold')\n",
    "#d = dict(G.degree)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(12,12)) \n",
    "#node_size = [v * 50 if v>2 else 5 for v in d.values()]\n",
    "#color_map = []\n",
    "#for v in d.values():\n",
    "#    if v<20:\n",
    "#        color_map.append(\"yellow\")\n",
    "#    elif v<50:\n",
    "#        color_map.append(\"green\")\n",
    "#    else:\n",
    "#        color_map.append(\"blue\")\n",
    "#nx.draw_random(G, with_labels=True, node_size=node_size, node_color=color_map)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h3>OBO dependency graph</h3>'))\n",
    "\n",
    "Gr = G\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "\n",
    "pos = nx.kamada_kawai_layout(Gr)\n",
    "\n",
    "for edge in Gr.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "node_x = []\n",
    "node_y = []\n",
    "node_count = len(Gr.nodes())\n",
    "for node in Gr.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_adjacencies = []\n",
    "node_sizes = []\n",
    "node_text = []\n",
    "for node, adjacencies in enumerate(Gr.adjacency()):\n",
    "    node_adjacencies.append(len(adjacencies[1]))\n",
    "    uses = len(adjacencies[1])\n",
    "    node_text.append(f'{adjacencies[0]} ({uses} uses)')\n",
    "    node_sizes.append((20*uses)/node_count+10)\n",
    "    \n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers',\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        # colorscale options\n",
    "        #'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
    "        #'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
    "        #'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=node_sizes,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='Node Connections',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "\n",
    "node_trace.marker.color = node_adjacencies\n",
    "node_trace.text = node_text\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
